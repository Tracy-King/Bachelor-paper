%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter01.tex for SJTU Master Thesis
%%==================================================

%\bibliographystyle{sjtu2}%[此处用于每章都生产参考文献]
\chapter{模型性能测试}
\label{chap:exper}



\section{数据集描述}

正确选择数据集是实验成功的关键，与模型要求相合的数据集可以助实验事半功倍。首先我们考虑了自己编写爬虫程序爬取数据的可能性，但是这种做法没办法取得标签信息，如果人工进行标签处理是一件十分枯燥且主观成分浓厚的事情，这对于实验是没有好处的。经过讨论，我们还是选择了使用别人收集好的数据集。前人的工作中有很多已经整理好的数据集，而且各有特色。Jindal等人 \parencite{Jindal:2008}发布了一个亚马逊的评论数据集，但是亚马逊平台与我们模型的目标不合；Li等人 \parencite{Li:2014}与大众点评公司合作，发布了一个大众点评的数据集，但是这个数据集没有包含店铺的位置信息；Rayana等人 \parencite{Rayana:2015}发布了一个自己搜集的Yelp数据集，包含店铺的评论信息和Yelp过滤系统给这些评论打的标签，但是这个数据集中的评论是按照店铺归类的。还有很多其他的数据集，都与我们实验的设想有很大差异。

最后，我们找到了Santosh等人 \parencite{Santosh:2016}使用过的Yelp数据集。这是一个部分标签的数据集，包含店铺的地址信息，而且评论信息也按照评论账户做了归类，非常适合我们的模型。数据集的标签部分中，每一条评论都被Yelp的过滤系统分类为了“虚假评论”和“普通评论”。数据集的相关数据如表~\ref{tbl:dataset}所示，数据集中一共含有760212条评论和16941个用户，其中带标签的评论有107624条，所有评论都被打过标签的用户有3142个。在107624条带标签评论中，20267条是虚假评论。这个数据集还有一个特色，那就是每一个被打过标签的用户的过滤比（即该用户所有评论中虚假评论的占比）都在0-20\%或90-100\%区间内。由于数据集本身并没有对用户进行标签处理，所以我们定义过滤比大于90\%的用户为水军用户，过滤比小于20\%的用户为普通用户。在这个分类标准下，3124个所有评论都被打过标签的用户中有1299个水军用户。此外，为了减少测试误差，一些发表评论数过低的用户将被过滤掉，不参与实际的计算。将评论数阈值设置为5的话，参与计算的用户数量将剩下11917个，所有评论都被打过标签的用户只剩下1796个。

\begin{table}[htbp]
	\caption[数据集相关数据]{数据集相关数据}
	\label{tbl:dataset}
	\centering
	\begin{tabular}{ccc}
		\toprule
		& 带标签的个数 & 总数  \\
		\midrule
		评论数  & 107624  & 760212  \\
		用户数  & 3142  &	16941 \\
		水军评论数 & 20267 & N/A \\
		水军用户数 & 1299 & N/A \\
		过滤后用户数 & 1796 & 11917 \\
		\bottomrule
	\end{tabular}
\end{table}

\section{实验描述}

本节我们将介绍实验的设置。实验环境的配置如表~\ref{tab:environment}所示。

\begin{table}[htbp]
	\caption[实验环境]{实验环境}
	\label{tab:environment}
	\centering
	\begin{tabular}{| c | c |}
		\hline
		\centering
		操作系统 &  Mac OS 10.12.6\\
		\hline
		\centering
		内存 & 8GB 1600MZ DDR3\\
		\hline
		\centering
		显卡 & Intel HD Graphics 6000 1536MB\\
		\hline
		\centering
		CPU & 1.6GHz Intel Core i5\\
		\hline
		\centering
		数据库软件 & Mysql v14.14\\
		\hline
		\centering
		模型编写 & Python 2.7 + pomegranate +
		scikit-learn\\
		\hline
	\end{tabular}
\end{table}

模型使用的地理位置特征是通过经纬度计算出来的，店铺的经纬度是使用一个名为\emph{geocoder}的python库，利用\emph{Arcgis}地图提供的地理位置编码功能从地址转换而来的。SpamTracer的模型参数是利用训练集训练得到的，测试是基于测试数据集的。训练集和测试数据集是数据集中包含标签部分内的不相交的两个集合。一个严重的问题是，数据集内的普通数据量和水军数据量是不平衡的，比例约为3:1，而实际上O2O平台的水军用户相比于普通用户也是占少数的那部分。在这样不平衡的数据集下，分类器需要能够抵挡数据的不平衡带来的影响。许多传统的分类算法在不平衡数据集中不能正常发挥，而SpamTracer可以经受大量误导数据的影响，准确地检测出小部分水军。

我们设计了对照组来测试SpamTracer的各项指标，这些对照组都是经典的分类方法。公平起见，我们选择的对照组都是监督型(Supervised)的算法，和SpamTracer的类型一致。对照组包含四个分类器：朴素贝叶斯NB、聚类算法AdaBoost、支持向量机SVM和多层感知机MLP(Multi-layer Perceptron)。对照组的模型使用用户的账户相关特征作为检测依据，包括评论数量、账号的朋友数量、账号的粉丝数量、被选为优质评论的数量等。所有模型在测试中都使用10层交叉验证(Cross Validation)以保证测试结果的可靠性。



\section{模型测试结果}




\section{水军行动规律验证}