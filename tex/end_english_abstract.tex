%# -*- coding: utf-8-unix -*-
\begin{bigabstract}

With the explosive growth of electronic commerce and social media, O2O (Online To Offline) commerce has become a heated topic in public. O2O refers to the use of online enticement to drive offline sales, and feedbacks from offline consumption can promote the online dissemination of products. As the feedback part in the O2O environment, reviews of experienced users can provide significant reference values for consumers and help them to make decisions. Opinions in reviews are essential to the evaluation and business volume of a target product in current O2O commercial platforms such as Amazon, Booking, and Yelp. Positive reviews can bring profits and fame, while negative ones are harmful to products. Due to the pursuit of interest, deceptive reviews and review spammers appeared. Moreover, the continuous and rapid evolution of social media makes spam themselves evolve very fast and pose a significant challenge to the community. It has been a common practice that shops tend to hire spammers to promote themselves secretly.  Those kinds of activities are called opinion spam.

At the early stage, methods of opinion spam were elementary and easy to identify. Meanwhile, commercial platforms realized the hazard of opinion spam and built their own filtering systems to find deceptive and inferior quality reviews. Those systems helped purify the disordered review environment, but they also prompted spammers to enrich their poor review contents. Even some skilled spammers were able to deceive the detecting system. As the elapse of time, spammers were becoming more and more cautious and tended to disguise as normal users, and those laggard traditional approaches wouldn't work efficiently anymore. The spotlight on spamming detection was gradually shifting from text contents to features and patterns. Some features were proved useful in spamming detection like time, ranking pattern, topics and activity volume. These new approaches did provide several new ideas in opinion spam detection field. 

Posting reviews is a random process. It means that the posting events are continuously and independently occurring at a constant average rate. Under such process, the related features will follow a particular distribution. Geolocation features were seldom used in spamming review detection, and geolocation is potential in spamming detection task. The related statistics and the frequency distribution of the location-related feature in spammers and non-spammers can be calculated and analyzed respectively, and the spamming detection problem can be solved by finding the distinctions between them. The statistics and the histograms of the features calculated on a labeled dataset are calculated based on a labeled dataset. The average value and standard deviation show the differences between two reviewer types. The feature distribution histograms demonstrate as double peak patterns both for spammers and non-spammers. The frequency distribution can be regarded as the overlap of several Gaussian distributions with different parameters under the log scale x-axis. The double peak distribution pattern is quite reasonable. In general, the range of human activity can be divided into two modes: home range and far range. Non-spammers tend to purchase near home, and sometimes go far places. It leads to the result that their geolocation features have the characteristic of double peaks. Although spammers also have two active ranges, they usually take a detour during spamming action since spammers don't pay much attention to the location order of spamming reviews. The location order of spamming reviews written by the same spammer is inconsistent with general behaviors of those belonging to non-spammers. This is the reason why both spammers and non-spammers have identical double peak patterns and different peak points and slopes. 

We proposed a supervised model \emph{SpamTracer} improved from the classic HMM to do spamming review detection by exploiting the geolocation features. It's more efficient to deal with data sequences rather than individual data samples because sequences can optimize the differences of action patterns and augment the performance. SpamTracer contains two HMM subchains and a label variable connecting two chains. Label variable is denoted by $0$ or $1$, where $0$ stands for non-spammers and $1$ stands for spammers. Two subchains represent non-spamming class and spamming class, and are trained by two kinds of data samples respectively. When a feature sequence comes, two subchains will calculate the possibility that generates this sequence. The value of the possibility is a score that measures the fitness between the feature sequence and the class of subchain. Supposing there is a feature sequence with unknown label, the model will calculate its scores under two subchains respectively, then choose the label by the subchain that gives a higher score. It's rational that the more probable label takes is the one that generates the observation sequence better. Our target is comparing the possibility of different label under a certain feature sequence. As a result, the calculation of probability under different subchains is proved practicable. SpamTracer is theoretically qualified as a supervised model and can make predictions. The prediction result given by SpamTracer can be regarded as a score measuring the fitness of data samples and different classes. 

After modeling the SpamTracer, we are going to discuss what can be discovered from the dataset with the assistance of SpamTracer. Several empirical conclusions are spreading in public about how to identify review spammers. For example, spamming reviews hold a large part in the beginning period of most online shops, and there are some periods when spammers regularly burst, etc. Besides, spammers tend to look for restaurants competing with others in the same business zone to persuade them to use their spamming services. As an owner of a restaurant in a hot business zone, it's easy for him to be forced to hire spammers when he finds that rivals around here are all working with spammers. This proposition can be validated by counting the shared spammers among restaurants close to each other. Contraposing those hypotheses, SpamTracer and the dataset will tell whether those empirical rules are rumor or truth. Our research mainly concerns three relations among spammers, time and geolocation:

\begin{enumerate*}
	\item Finding the connection between the number of daily spamming reviews and the date period. We can obtain the bursting time of spammers in every year and every week.
	\item Finding the relation between the number of daily spamming reviews and shop opening days. We can know exactly in which stage restaurants are likely to hire spammers.
	\item Finding the relation between the interval distance of two restaurants and the number of spammers they share. We can obtain the number and ratio of shared spammers.
\end{enumerate*}


The geolocation features are calculated by latitudes and longitudes of every review shop. They are translated from \emph{Arcgis} Map addresses by a python package named \emph{geocoder}. Parameters of SpamTracer are trained from the training dataset, and the evaluation is based on the testing dataset. Training dataset and testing dataset are disjointed parts in labeled data. The ratio of spammers and non-spammers in labeled data is unbalanced, which is about 1:3. The number of spammers in real O2O platforms is also a minority. And classifiers are required to hold the resistance to the interference from the unbalanced dataset. Many traditional classification algorithms can't perform well in such situation while SpamTracer can tolerate the impact of large misleading data and recognize the minority spammers exactly.

SpamTracer needs to be compared with other existing excellent approaches to show its advantages in performance. Impartially, some traditional supervised classifiers are selected as the comparison group since SpamTracer is supervised. The comparison group contains four typical classification algorithms: NB(Naive Bayes), AdaBoost Classifier, SVM(Support Vector Machine) and MLP( Multi-layer Perceptron). Those comparison models receive several account characteristics(i.e., friends number, reviews number, etc.) from dataset and output the prediction of spammer or non-spammer. Besides, our experiment uses a 10-fold CV(Cross Validation) to guarantee the evaluation result.

The evaluation of models is based on four acknowledged standard performance measures: Accuracy, Precision, Recall, and F1-score. In conclusion, SpamTracer holds excellent stability and performs above the average in all four measures under an unbalanced dataset. Interfered by the unbalanced dataset environment, those classical approaches can't find a compromise among those measures. If we need a stable and precise review filter in O2O platforms, they will not be a good choice since they are likely to miscalculate many normal users or let off many spammers. It's undeniable that SpamTracer will be a better choice for spamming review detection task.

As for the restriction of the performance of SpamTracer, we have some ideas. First, the length of sequences is vital to the performance. The chain structure of SpamTracer determines that the longer data sequences are, the better performance will be. Besides, the scale of dataset also puts a limitation on their performance. 

After our experiment of finding the regularities of spamming actions, we found that Spammers tend to burst in summer days of a year and on weekends of a week. The tourism data reflects a phenomenon that summer is a busy season for traveling. Excessive tourist flows stimulate shop owners to hire more spammers to gain popularity and income. Besides, Spammers most appear in the early stage of shop opening days, and gradually decrease as the elapse of opening days. We also found that even there exist some shops whose half of reviews are posted by spammers. It validates a common practice: shops tend to hire spammers to promote themselves secretly. Finally, we discovered a regularity that the amount of shared spammers is inversely proportional to the interval distance between two shops. However, shared spammers only hold a limited percentage of spamming actions. Shared spammers don't worth paying much attention to.

To draw a conclusion, in this thesis, we conducted a research about exploiting geolocation to detect review spammers in O2O commercial platforms. We improved a novel detection model, SpamTracer, based on Hidden Markov Model to detect review spammers by exploiting the unique distinctions of location features between spammers and non-spammers. Our evaluation is based on a large scale Yelp dataset and demonstrates that our approach can take spamming review detection task with excellent accuracy and stability. Also, we discovered some significant regularities in spamming actions regarding time and location. Spammers tend to launch spamming actions in the summer season of a year, on weekends of a week, and in the beginning stage of shop opening days. We also found that there existed a negative correlation between the number of shared spammers and the interval distance between two shops. Our experiment is guaranteed by 694,020 labeled reviews and 228,859 shops.


\end{bigabstract}